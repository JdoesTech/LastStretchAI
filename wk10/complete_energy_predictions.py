# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z9ySyCt04bP06nV3pQMeDEX7HVmK-smA
"""

#!pip install streamlit

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
#import streamlit as st

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, mean_absolute_error , mean_squared_error, r2_score, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import LSTM

import pickle
import joblib
import kagglehub
import os

path= kagglehub.dataset_download("ajinilpatel/energy-consumption-prediction")
print("Path to dataset files:", path)
#kaggle repo: https://www.kaggle.com/datasets/ajinilpatel/energy-consumption-prediction/data

#define path to file
os.listdir(path)
file_path=os.path.join(path, "Energy_consumption_dataset.csv")
print(file_path)

#load dataset as dataframe
df_main=pd.read_csv(file_path)
print(df_main.info())
print(df_main.head())

#create a working copy to manipulate while maintaining original datafram
df=df_main.copy()
#drop columns with more than half of their entries as Null
df=df.loc[:, df.isna().mean() < 0.5]
#drop records with null values in the Energy Consumption column
df=df.dropna(subset=["EnergyConsumption"])
#cast the Energy Consumption column as a float type for numerical analysis
y=df["EnergyConsumption"].astype(float)
#X= df.drop(columns=[col for col in ["EnergyConsumption", "EnergyBin"]if col in df.columns])
#drop the Energy Consumption column from the base frame to train AI with
X=df.drop(columns=["EnergyConsumption"])
#make words binary
X=pd.get_dummies(X, drop_first=True)
print(f"X shape: {X.shape}")
feature_name=X.columns.tolist()

#Monthly stats on Energy Consumption
sns.boxplot(data=df, x="Month", y="EnergyConsumption")
plt.title("Energy Consumption by Month")
plt.show()

#Effect of temperature on Energy consumption
rounded_temp= round(df["Temperature"])
plt.figure(figsize=(10, 6))
sns.boxplot(x=rounded_temp, y=df["EnergyConsumption"])
plt.title("Energy Consumption vs Temperature")
plt.xlabel("Rounded Temperature")
plt.ylabel("Energy Consumption")
plt.show()

#without rounding off
plt.figure(figsize=(10, 6))
sns.scatterplot(data=df.head(1000), x="Temperature", y="EnergyConsumption", alpha=0.5)
plt.title("Energy Consumption vs Temperature")
plt.xlabel("Temperature")
plt.ylabel("Energy Consumption")
plt.show()

#Effect of the day
plt.figure(figsize=(10, 6))
sns.lineplot(data=df, x="Hour", y="EnergyConsumption", hue="DayOfWeek")
plt.title("Energy Consumption by Day")
plt.xlabel("Day")
plt.ylabel("Energy Consumption")
plt.show()



def two_stage_split(X, y, holdout_frac=0.2, test_frac_within=0.2, random_state=42):
  X_hold, X_rest, y_hold, y_rest = train_test_split(X, y, test_size=1-holdout_frac, random_state=random_state)
  X_train, X_test, y_train, y_test = train_test_split(X_rest, y_rest, test_size=test_frac_within, random_state=random_state)
  return (X_train, X_test, X_hold, y_train, y_test, y_hold)

#function to domicile regression
def report_regression(y_true, y_pred, prefix=''):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = mse ** 0.5
    r2 = r2_score(y_true, y_pred)
    print(f"{prefix} MAE: {mae:.4f}")
    print(f"{prefix} MSE: {mse:.4f}")
    print(f"{prefix} RMSE: {rmse:.4f}")
    print(f"{prefix} R^2: {r2:.4f}")
    return {'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2}

def show_cv_scores(model, X, y, cv=5, scoring='neg_mean_squared_error'):
    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)
    if scoring.startswith('neg_'):
        scores = -scores
    print(f"CV ({scoring}) mean: {scores.mean():.4f}, std: {scores.std():.4f}")
    return scores

def plot_predictions(y_true, y_pred, title=''):
  plt.figure(figsize=(8, 6))
  sns.scatterplot(x=y_true, y=y_pred, alpha=0.5)
  #plt.scatter(y_true, y_pred, alpha=0.5)
  plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--') #'k--', lw=2
  plt.xlabel('True Values')
  plt.ylabel('Predicted Values')
  plt.title(title)
  plt.show()

def plot_heatmap(df, title=''):
  plt.figure(figsize=(10, 8))
  sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
  plt.title(title)
  plt.show()

def plot_residual(y_pred, y_test, title=''):
  plt.figure(figsize=(8, 6))
  sns.residplot(x=y_pred, y=y_pred-y_test, lowess=True)
  plt.axhline(y=0, color='r', linestyle='--')
  plt.xlabel('Predicted Values')
  plt.ylabel('Residuals')
  plt.title(title)
  plt.show()

def forecast(y_test, y_pred):
  plt.figure(figsize=(10,5))
  plt.plot(range(len(y_test)), label='Actual')
  plt.plot(range(len(y_test)), y_pred, label='Predicted')
  plt.title("Energy Demand Forecasting")
  plt.xlabel("Time")
  plt.ylabel("Energy Consumption (kWh)")
  plt.legend()
  plt.show()

#Split data
X_train, X_test, X_hold, y_train, y_test, y_hold = two_stage_split(X.values, y.values, holdout_frac=0.2, test_frac_within=0.2, random_state=42)

scaler= StandardScaler()
X_train_sc= scaler.fit_transform(X_train)
X_test_sc= scaler.transform(X_test)
X_hold_sc= scaler.transform(X_hold)

#linear regression
rgr= LinearRegression()
rgr.fit(X_train_sc, y_train)
y_pred_test= rgr.predict(X_test_sc)
print('LinearRegression on test set:')
report_regression(y_test, y_pred_test, prefix='Test')
print('\nLinearRegression cross-validation (on training set):')
show_cv_scores(rgr, X_train_sc, y_train, cv=5, scoring='neg_mean_squared_error')

y_hold_test=rgr.predict(X_hold_sc)
print("LinearRegression on hold out set:")
report_regression(y_hold, y_hold_test, prefix="Holdout")

plot_predictions(y_test, y_pred_test, title="Test Set: Predicted vs Actual")
plot_residual(y_pred_test, y_test, title="Test Set: Predicted vs Residual")
forecast(y_test, y_pred_test)

print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)

#Random Forest
rnf=RandomForestRegressor(n_estimators=100)
rnf.fit(X_train, y_train)
y_pred_test_rnf= rnf.predict(X_test)
print("Random Forest on test set: ")
report_regression(y_test, y_pred_test_rnf, prefix="Test")
print("\nRandom Forest cross-validation (on training set):")
show_cv_scores(rnf, X_train, y_train, cv=5, scoring="neg_mean_squared_error")

y_hold_test_rnf= rnf.predict(X_hold)
print("Random Forest on hold out set: ")
report_regression(y_hold, y_hold_test_rnf, prefix="Holdout")
show_cv_scores(rnf, X_hold, y_hold, cv=5, scoring="neg_mean_squared_error")

importances = rnf.feature_importances_
feature_names = X.columns.tolist()
sns.barplot(x=importances, y=feature_names)
plt.title("Feature Importance in Energy Forecasting")
plt.show()

forecast(y_test, y_pred_test_rnf)

df_class=df.copy()
bin_ends=np.arange(0, df_class["EnergyConsumption"].max()+5, 5)
df_class["EnergyBin"] = pd.cut(df_class["EnergyConsumption"], bins=bin_ends, labels=False)
Xc= df_class.drop(columns=["EnergyConsumption", "EnergyBin"])
yc= df_class["EnergyBin"]
Xc=pd.get_dummies(Xc, drop_first=True)
X_train, X_test, X_hold, y_train, y_test, y_hold = two_stage_split(Xc.values, yc.values, holdout_frac=0.2, test_frac_within=0.2, random_state=42)
clf= RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred_test_clf= clf.predict(X_test)
print("Random Forest Classifier on test set ")
print("Accuracy: ", accuracy_score(y_test, y_pred_test_clf))
print("Precision: ", precision_score(y_test, y_pred_test_clf, average="weighted"))
print("Recall: ", recall_score(y_test, y_pred_test_clf, average="weighted"))
print("F1 Score: ", f1_score(y_test, y_pred_test_clf, average="weighted"))
print("\nClassification Report: ")
print(classification_report(y_test, y_pred_test_clf, zero_division=0))
cm_pred=confusion_matrix(y_test, y_pred_test_clf)


y_hold_test_clf= clf.predict(X_hold)
print("Random Forest Classifier on hold out set ")
print("Accuracy: ", accuracy_score(y_hold, y_hold_test_clf))
print("Precision: ", precision_score(y_hold, y_hold_test_clf, average="weighted"))
print("Recall: ", recall_score(y_hold, y_hold_test_clf, average="weighted"))
print("F1 Score: ", f1_score(y_hold, y_hold_test_clf, average="weighted"))
print("\nClassification Report: ")
print(classification_report(y_hold, y_hold_test_clf, zero_division=0))
cm_hold=(confusion_matrix(y_hold, y_hold_test_clf))

sns.heatmap(cm_hold, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix for Holdout Set")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

y_lstm= df["EnergyConsumption"].astype(float)
x_lstm =df.drop(columns=["EnergyConsumption", "EnergyBin"], errors="ignore")
x_lstm = pd.get_dummies(x_lstm, drop_first=True)

X_train, X_test, X_hold, y_train, y_test, y_hold = two_stage_split(x_lstm.values, y_lstm.values, holdout_frac=0.2, test_frac_within=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_hold = scaler.transform(X_hold)

# Reshape data for LSTM [samples, time_steps, features]
X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))
X_hold = X_hold.reshape((X_hold.shape[0], 1, X_hold.shape[1]))

# Define model layers explicitly
lstm_layer = LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)
dropout_layer = Dropout(0.3)
dense1_layer = Dense(32, activation="relu")
output_layer = Dense(1)

model = Sequential([lstm_layer, dropout_layer, dense1_layer, output_layer])

model.compile(optimizer="adam", loss="mse", metrics=["mae"])

early_stop = EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)
history = model.fit( X_train, y_train, epochs=8, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)

y_pred_test_lstm= model.predict(X_test).flatten()
print("LSTM on test set: ")
report_regression(y_test, y_pred_test_lstm, prefix="Test")

y_pred_hold_lstm= model.predict(X_hold).flatten()
print("LSTM on hold out set: ")
report_regression(y_hold, y_pred_hold_lstm, prefix="Holdout")

plot_predictions(y_test, y_pred_test_lstm, title="Test Set: Predicted vs Actual")
plot_heatmap(pd.DataFrame(history.history), title="Training History")
plot_predictions(y_hold, y_pred_hold_lstm, title="Holdout Set: Predicted vs Actual")
plot_heatmap(pd.DataFrame(history.history), title="Training History")
forecast(y_test, y_pred_test_lstm)