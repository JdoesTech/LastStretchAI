# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z9ySyCt04bP06nV3pQMeDEX7HVmK-smA
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, mean_absolute_error , mean_squared_error, r2_score, accuracy_score, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.preprocessing import StandardScaler

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import LSTM

import pickle
import joblib
import kagglehub
import os

path= kagglehub.dataset_download("ajinilpatel/energy-consumption-prediction")
print("Path to dataset files:", path)
#kaggle repo: https://www.kaggle.com/datasets/ajinilpatel/energy-consumption-prediction/data

#define path to file
os.listdir(path)
file_path=os.path.join(path, "Energy_consumption_dataset.csv")
print(file_path)

#load dataset as dataframe
df_main=pd.read_csv(file_path)
df_main.info()
df_main.head()

#create a working copy to manipulate while maintaining original datafram
df=df_main.copy()
#drop columns with more than half of their entries as Null
df=df.loc[:, df.isna().mean() < 0.5]
#drop records with null values in the Energy Consumption column
df=df.dropna(subset=["EnergyConsumption"])
#cast the Energy Consumption column as a float type for numerical analysis
y=df["EnergyConsumption"].astype(float)
#X= df.drop(columns=[col for col in ["EnergyConsumption", "EnergyBin"]if col in df.columns])
#drop the Energy Consumption column from the base frame to train AI with
X=df.drop(columns=["EnergyConsumption"])
#make words binary
X=pd.get_dummies(X, drop_first=True)
print(f"X shape: {X.shape}")
feature_name=X.columns.tolist()

def two_stage_split(X, y, holdout_frac=0.2, test_frac_within=0.2, random_state=42):
  X_hold, X_rest, y_hold, y_rest = train_test_split(X, y, test_size=1-holdout_frac, random_state=random_state)
  X_train, X_test, y_train, y_test = train_test_split(X_rest, y_rest, test_size=test_frac_within, random_state=random_state)
  return (X_train, X_test, X_hold, y_train, y_test, y_hold)

#function to domicile regression
def report_regression(y_true, y_pred, prefix=''):
    mae = mean_absolute_error(y_true, y_pred)
    mse = mean_squared_error(y_true, y_pred)
    rmse = mse ** 0.5
    r2 = r2_score(y_true, y_pred)
    print(f"{prefix} MAE: {mae:.4f}")
    print(f"{prefix} MSE: {mse:.4f}")
    print(f"{prefix} RMSE: {rmse:.4f}")
    print(f"{prefix} R^2: {r2:.4f}")
    return {'mae': mae, 'mse': mse, 'rmse': rmse, 'r2': r2}

def show_cv_scores(model, X, y, cv=5, scoring='neg_mean_squared_error'):
    scores = cross_val_score(model, X, y, cv=cv, scoring=scoring)
    if scoring.startswith('neg_'):
        scores = -scores
    print(f"CV ({scoring}) mean: {scores.mean():.4f}, std: {scores.std():.4f}")
    return scores

def plot_predictions(y_true, y_pred, title=''):
  plt.figure(figsize=(8, 6))
  sns.scatterplot(x=y_true, y=y_pred, alpha=0.5)
  #plt.scatter(y_true, y_pred, alpha=0.5)
  plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--') #'k--', lw=2
  plt.xlabel('True Values')
  plt.ylabel('Predicted Values')
  plt.title(title)
  plt.show()

#Split data
X_train, X_test, X_hold, y_train, y_test, y_hold = two_stage_split(X.values, y.values, holdout_frac=0.2, test_frac_within=0.2, random_state=42)

scaler= StandardScaler()
X_train_sc= scaler.fit_transform(X_train)
X_test_sc= scaler.transform(X_test)
X_hold_sc= scaler.transform(X_hold)

#linear regression
rgr= LinearRegression()
rgr.fit(X_train_sc, y_train)
y_pred_test= rgr.predict(X_test_sc)
print('LinearRegression on test set:')
report_regression(y_test, y_pred_test, prefix='Test')
print('\nLinearRegression cross-validation (on training set):')
show_cv_scores(rgr, X_train_sc, y_train, cv=5, scoring='neg_mean_squared_error')

y_hold_test=rgr.predict(X_hold_sc)
print("LinearRegression on hold out set:")
report_regression(y_hold, y_hold_test, prefix="Holdout")

#Random Forest
rnf=RandomForestRegressor(n_estimators=100)
rnf.fit(X_train, y_train)
y_pred_test_rnf= rnf.predict(X_test)
print("Random Forest on test set: ")
report_regression(y_test, y_pred_test_rnf, prefix="Test")
print("\nRandom Forest cross-validation (on training set):")
show_cv_scores(rnf, X_train, y_train, cv=5, scoring="neg_mean_squared_error")

y_hold_test_rnf= rnf.predict(X_hold)
print("Random Forest on hold out set: ")
report_regression(y_hold, y_hold_test_rnf, prefix="Holdout")
show_cv_scores(rnf, X_hold, y_hold, cv=5, scoring="neg_mean_squared_error")

df_class=df.copy()
bin_ends=np.arange(0, df_class["EnergyConsumption"].max()+5, 5)
df_class["EnergyBin"] = pd.cut(df_class["EnergyConsumption"], bins=bin_ends, labels=False)
Xc= df_class.drop(columns=["EnergyConsumption", "EnergyBin"])
yc= df_class["EnergyBin"]
Xc=pd.get_dummies(Xc, drop_first=True)
X_train, X_test, X_hold, y_train, y_test, y_hold = two_stage_split(Xc.values, yc.values, holdout_frac=0.2, test_frac_within=0.2, random_state=42)
clf= RandomForestClassifier(n_estimators=100)
clf.fit(X_train, y_train)
y_pred_test_clf= clf.predict(X_test)
print("Random Forest Classifier on test set ")
print("Accuracy: ", accuracy_score(y_test, y_pred_test_clf))
print("Precision: ", precision_score(y_test, y_pred_test_clf, average="weighted"))
print("Recall: ", recall_score(y_test, y_pred_test_clf, average="weighted"))
print("F1 Score: ", f1_score(y_test, y_pred_test_clf, average="weighted"))
print("\nClassification Report: ")
print(classification_report(y_test, y_pred_test_clf, zero_division=0))
cm_pred=confusion_matrix(y_test, y_pred_test_clf)


y_hold_test_clf= clf.predict(X_hold)
print("Random Forest Classifier on hold out set ")
print("Accuracy: ", accuracy_score(y_hold, y_hold_test_clf))
print("Precision: ", precision_score(y_hold, y_hold_test_clf, average="weighted"))
print("Recall: ", recall_score(y_hold, y_hold_test_clf, average="weighted"))
print("F1 Score: ", f1_score(y_hold, y_hold_test_clf, average="weighted"))
print("\nClassification Report: ")
print(classification_report(y_hold, y_hold_test_clf, zero_division=0))
cm_hold=(confusion_matrix(y_hold, y_hold_test_clf))

sns.heatmap(cm_hold, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix for Holdout Set")
plt.xlabel("Predicted Class")
plt.ylabel("True Class")
plt.show()

y_lstm= df["EnergyConsumption"].astype(float)
x_lstm =df.drop(columns=["EnergyConsumption", "EnergyBin"], errors="ignore")
x_lstm = pd.get_dummies(x_lstm, drop_first=True)

X_train, X_test, X_hold, y_train, y_test, y_hold = two_stage_split(x_lstm.values, y_lstm.values, holdout_frac=0.2, test_frac_within=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_hold = scaler.transform(X_hold)

# Reshape data for LSTM [samples, time_steps, features]
#X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))
#X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))
#X_hold = X_hold.reshape((X_hold.shape[0], 1, X_hold.shape[1]))

# Define model layers explicitly
lstm_layer = LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=False)
dropout_layer = Dropout(0.3)
dense1_layer = Dense(32, activation="relu")
output_layer = Dense(1)

model = Sequential([lstm_layer, dropout_layer, dense1_layer, output_layer])

model.compile(optimizer="adam", loss="mse", metrics=["mae"])

early_stop = EarlyStopping(monitor="val_loss", patience=10, restore_best_weights=True)
history = model.fit( X_train, y_train, epochs=45, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stop], verbose=1)

y_pred_test_lstm= model.predict(X_test).flatten()
print("LSTM on test set: ")
report_regression(y_test, y_pred_test_lstm, prefix="Test")

y_pred_hold_lstm= model.predict(X_hold).flatten()
print("LSTM on hold out set: ")
report_regression(y_hold, y_pred_hold_lstm, prefix="Holdout")

plot_predictions(y_test, y_pred_test_lstm, title="Test Set: Predicted vs Actual")
plot_predictions(y_hold, y_pred_hold_lstm, title="Holdout Set: Predicted vs Actual")